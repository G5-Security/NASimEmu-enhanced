{"timestamp": 1760727895.8006535, "train_step": 100, "env_steps_total": 12800, "loss": 11.24506918589274, "grad_mean": 0.19530436123410863, "grad_min": 0.09959082305431366, "grad_max": 0.3346589207649231, "entropy_mean": 5.9845604197184255, "entropy_min": 4.792537530263265, "entropy_max": 6.185108184814453, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.1092792970631272, "reward_avg_episodes": -43.711700439453125, "eplen_avg": 400.0, "captured_avg": 5.859375}, "eval_tst": {"reward_avg": -0.10860351582779555, "reward_avg_episodes": -43.441383361816406, "eplen_avg": 400.0, "captured_avg": 5.9375}}
{"timestamp": 1760728027.165902, "train_step": 200, "env_steps_total": 25600, "loss": 11.371009508768717, "grad_mean": 0.1514640612155199, "grad_min": 0.10779475917418797, "grad_max": 0.21871092915534973, "entropy_mean": 6.060897879600524, "entropy_min": 5.977504730224609, "entropy_max": 6.129569371541341, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.10901367210876209, "reward_avg_episodes": -43.60545349121094, "eplen_avg": 400.0, "captured_avg": 6.1796875}, "eval_tst": {"reward_avg": -0.10808398463111372, "reward_avg_episodes": -43.23358154296875, "eplen_avg": 400.0, "captured_avg": 6.5078125}}
{"timestamp": 1760728235.3712642, "train_step": 100, "env_steps_total": 12800, "loss": 10.887699127197266, "grad_mean": 0.17399379111826418, "grad_min": 0.08444422731796901, "grad_max": 0.25106685360272724, "entropy_mean": 5.857555998166402, "entropy_min": 4.805340925852458, "entropy_max": 6.003950754801433, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.14518847657222053, "reward_avg_episodes": -58.075355529785156, "eplen_avg": 400.0, "captured_avg": 3.6484375}, "eval_tst": {"reward_avg": -0.14526660159055607, "reward_avg_episodes": -58.10661315917969, "eplen_avg": 400.0, "captured_avg": 3.578125}}
{"timestamp": 1760728345.2624342, "train_step": 200, "env_steps_total": 25600, "loss": 10.78066380818685, "grad_mean": 0.14171910914282004, "grad_min": 0.1032940944035848, "grad_max": 0.22615788380304971, "entropy_mean": 5.929200353622437, "entropy_min": 5.847137928009033, "entropy_max": 6.0181355476379395, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.14482324219628942, "reward_avg_episodes": -57.92924499511719, "eplen_avg": 400.0, "captured_avg": 3.1484375}, "eval_tst": {"reward_avg": -0.14493554687939483, "reward_avg_episodes": -57.97416687011719, "eplen_avg": 400.0, "captured_avg": 3.2421875}}
{"timestamp": 1760728457.088163, "train_step": 300, "env_steps_total": 38400, "loss": 10.916102727254232, "grad_mean": 0.1304108084986607, "grad_min": 0.09680096805095673, "grad_max": 0.20718309779961905, "entropy_mean": 5.940417025883993, "entropy_min": 5.848088105519612, "entropy_max": 6.0194220542907715, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.1482353515627329, "reward_avg_episodes": -59.294097900390625, "eplen_avg": 400.0, "captured_avg": 3.578125}, "eval_tst": {"reward_avg": -0.14890527344611482, "reward_avg_episodes": -59.56208038330078, "eplen_avg": 400.0, "captured_avg": 3.5390625}}
{"timestamp": 1760728569.2307265, "train_step": 400, "env_steps_total": 51200, "loss": 10.90300718943278, "grad_mean": 0.12117561921477318, "grad_min": 0.08672895282506943, "grad_max": 0.18029837807019553, "entropy_mean": 5.949993492762247, "entropy_min": 5.883592128753662, "entropy_max": 6.040744145711263, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.14359570313306189, "reward_avg_episodes": -57.43824768066406, "eplen_avg": 400.0, "captured_avg": 3.515625}, "eval_tst": {"reward_avg": -0.14258300782865269, "reward_avg_episodes": -57.03316879272461, "eplen_avg": 400.0, "captured_avg": 3.65625}}
{"timestamp": 1760728679.5580175, "train_step": 500, "env_steps_total": 64000, "loss": 10.892284075419107, "grad_mean": 0.11188479696710905, "grad_min": 0.0777139738202095, "grad_max": 0.14713857074578604, "entropy_mean": 5.945590742429097, "entropy_min": 5.863798936208089, "entropy_max": 6.02094030380249, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.1430380859599683, "reward_avg_episodes": -57.215187072753906, "eplen_avg": 400.0, "captured_avg": 3.53125}, "eval_tst": {"reward_avg": -0.14374316405001436, "reward_avg_episodes": -57.497222900390625, "eplen_avg": 400.0, "captured_avg": 3.453125}}
{"timestamp": 1760728789.6423614, "train_step": 600, "env_steps_total": 76800, "loss": 10.828601837158203, "grad_mean": 0.10287703265746435, "grad_min": 0.07520415633916855, "grad_max": 0.14450915157794952, "entropy_mean": 5.909944073359172, "entropy_min": 5.8402635256449384, "entropy_max": 5.978391170501709, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.14740136718138813, "reward_avg_episodes": -58.96051788330078, "eplen_avg": 400.0, "captured_avg": 3.640625}, "eval_tst": {"reward_avg": -0.14794238282894362, "reward_avg_episodes": -59.176918029785156, "eplen_avg": 400.0, "captured_avg": 3.5}}
{"timestamp": 1760729019.9697356, "train_step": 100, "env_steps_total": 12800, "loss": 11.36718781789144, "grad_mean": 0.1724451747288306, "grad_min": 0.09786205490430196, "grad_max": 0.27306602895259857, "entropy_mean": 5.968920839627584, "entropy_min": 4.81718111038208, "entropy_max": 6.176275889078776, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.13741503899253454, "reward_avg_episodes": -54.965980529785156, "eplen_avg": 400.0, "captured_avg": 6.7109375}, "eval_tst": {"reward_avg": -0.13755859371446427, "reward_avg_episodes": -55.02339553833008, "eplen_avg": 400.0, "captured_avg": 6.6171875}}
{"timestamp": 1760729143.6999896, "train_step": 200, "env_steps_total": 25600, "loss": 11.715630531311035, "grad_mean": 0.1653984532256921, "grad_min": 0.12724000960588455, "grad_max": 0.2222337673107783, "entropy_mean": 6.094247515996297, "entropy_min": 5.958133061726888, "entropy_max": 6.234136899312337, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.13419335925963233, "reward_avg_episodes": -53.677330017089844, "eplen_avg": 400.0, "captured_avg": 7.5078125}, "eval_tst": {"reward_avg": -0.13324023429656534, "reward_avg_episodes": -53.29606628417969, "eplen_avg": 400.0, "captured_avg": 7.6875}}
{"timestamp": 1760729265.6561282, "train_step": 300, "env_steps_total": 38400, "loss": 11.547584533691406, "grad_mean": 0.12975374589363736, "grad_min": 0.08847621828317642, "grad_max": 0.22242834170659384, "entropy_mean": 6.086947838465374, "entropy_min": 5.986788113911946, "entropy_max": 6.216233253479004, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.1339121093080902, "reward_avg_episodes": -53.56481170654297, "eplen_avg": 400.0, "captured_avg": 7.6484375}, "eval_tst": {"reward_avg": -0.13525781243463258, "reward_avg_episodes": -54.103092193603516, "eplen_avg": 400.0, "captured_avg": 7.2421875}}
{"timestamp": 1760729389.0752413, "train_step": 400, "env_steps_total": 51200, "loss": 11.687989552815756, "grad_mean": 0.1366980020950238, "grad_min": 0.09032553931077321, "grad_max": 0.202244703968366, "entropy_mean": 6.101195023854575, "entropy_min": 6.003408114115397, "entropy_max": 6.191151301066081, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.13247265619144297, "reward_avg_episodes": -52.98902893066406, "eplen_avg": 400.0, "captured_avg": 7.28125}, "eval_tst": {"reward_avg": -0.1330751952464926, "reward_avg_episodes": -53.23004913330078, "eplen_avg": 400.0, "captured_avg": 7.4140625}}
{"timestamp": 1760729511.343883, "train_step": 500, "env_steps_total": 64000, "loss": 11.335232416788736, "grad_mean": 0.12083984551330408, "grad_min": 0.0826655129591624, "grad_max": 0.19788308441638947, "entropy_mean": 6.081495501200359, "entropy_min": 5.947574774424235, "entropy_max": 6.204237143198649, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.13362304679633227, "reward_avg_episodes": -53.44918441772461, "eplen_avg": 400.0, "captured_avg": 7.6796875}, "eval_tst": {"reward_avg": -0.1348017577448918, "reward_avg_episodes": -53.92066955566406, "eplen_avg": 400.0, "captured_avg": 7.25}}
{"timestamp": 1760729638.7527506, "train_step": 600, "env_steps_total": 76800, "loss": 11.76218064626058, "grad_mean": 0.11934636866052946, "grad_min": 0.09085334589083989, "grad_max": 0.189372385541598, "entropy_mean": 6.090239264170329, "entropy_min": 5.9826340675354, "entropy_max": 6.216793219248454, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.13547167960272047, "reward_avg_episodes": -54.18864059448242, "eplen_avg": 400.0, "captured_avg": 7.4765625}, "eval_tst": {"reward_avg": -0.13539062493320675, "reward_avg_episodes": -54.156227111816406, "eplen_avg": 400.0, "captured_avg": 7.640625}}
{"timestamp": 1761410023.9016755, "train_step": 100, "env_steps_total": 12800, "loss": 10.79781405131022, "grad_mean": 0.1768573414161801, "grad_min": 0.07408752168218295, "grad_max": 0.2501612901687622, "entropy_mean": 5.885670601526897, "entropy_min": 4.820933024088542, "entropy_max": 6.091254711151123, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.13496386726718634, "reward_avg_episodes": -53.98544692993164, "eplen_avg": 400.0, "captured_avg": 3.34375}, "eval_tst": {"reward_avg": -0.13382910165551576, "reward_avg_episodes": -53.53154754638672, "eplen_avg": 400.0, "captured_avg": 3.5390625}}
{"timestamp": 1761410142.8634844, "train_step": 200, "env_steps_total": 25600, "loss": 10.812748591105143, "grad_mean": 0.13159690623482068, "grad_min": 0.09612410515546799, "grad_max": 0.1766163557767868, "entropy_mean": 5.975423898696899, "entropy_min": 5.867699940999349, "entropy_max": 6.095889727274577, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.131475586030574, "reward_avg_episodes": -52.59014129638672, "eplen_avg": 400.0, "captured_avg": 3.90625}, "eval_tst": {"reward_avg": -0.1315478516329021, "reward_avg_episodes": -52.619041442871094, "eplen_avg": 400.0, "captured_avg": 3.8984375}}
{"timestamp": 1761410259.4080617, "train_step": 300, "env_steps_total": 38400, "loss": 10.657687187194824, "grad_mean": 0.11748084830741087, "grad_min": 0.07941222687562306, "grad_max": 0.16710436344146729, "entropy_mean": 5.9436521752675375, "entropy_min": 5.813793659210205, "entropy_max": 6.094606399536133, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.13525000009182234, "reward_avg_episodes": -54.099910736083984, "eplen_avg": 400.0, "captured_avg": 3.6640625}, "eval_tst": {"reward_avg": -0.13523339850426402, "reward_avg_episodes": -54.09326171875, "eplen_avg": 400.0, "captured_avg": 3.5546875}}
{"timestamp": 1761410424.9849644, "train_step": 100, "env_steps_total": 12800, "loss": 11.119599342346191, "grad_mean": 0.19337791815400124, "grad_min": 0.08955064167579015, "grad_max": 0.3227965732415517, "entropy_mean": 5.988511560757954, "entropy_min": 4.800747871398926, "entropy_max": 6.22953732808431, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.13050585942121692, "reward_avg_episodes": -52.20226287841797, "eplen_avg": 400.0, "captured_avg": 6.4296875}, "eval_tst": {"reward_avg": -0.12969726566202003, "reward_avg_episodes": -51.878814697265625, "eplen_avg": 400.0, "captured_avg": 6.6484375}}
{"timestamp": 1761410607.683328, "train_step": 100, "env_steps_total": 12800, "loss": 11.640162467956543, "grad_mean": 0.2156946394840876, "grad_min": 0.0910734310746193, "grad_max": 0.29800207912921906, "entropy_mean": 6.064159412384033, "entropy_min": 4.834458827972412, "entropy_max": 6.2953033447265625, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.12158593754848694, "reward_avg_episodes": -48.63429641723633, "eplen_avg": 400.0, "captured_avg": 7.234375}, "eval_tst": {"reward_avg": -0.12077050783485166, "reward_avg_episodes": -48.30812454223633, "eplen_avg": 400.0, "captured_avg": 7.3125}}
{"timestamp": 1761410991.8873453, "train_step": 100, "env_steps_total": 12800, "loss": 11.30072275797526, "grad_mean": 0.19357221166292823, "grad_min": 0.09812090049187343, "grad_max": 0.37986187140146893, "entropy_mean": 5.99487200419108, "entropy_min": 4.833804448445638, "entropy_max": 6.160360018412272, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.12339648438690354, "reward_avg_episodes": -49.3585090637207, "eplen_avg": 400.0, "captured_avg": 7.5078125}, "eval_tst": {"reward_avg": -0.12315039066513402, "reward_avg_episodes": -49.26008605957031, "eplen_avg": 400.0, "captured_avg": 7.484375}}
{"timestamp": 1761411124.9260511, "train_step": 200, "env_steps_total": 25600, "loss": 11.036239624023438, "grad_mean": 0.15436535475154717, "grad_min": 0.11001083254814148, "grad_max": 0.2588719626267751, "entropy_mean": 6.08622457186381, "entropy_min": 6.009553750356038, "entropy_max": 6.1711344718933105, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.11935449219166175, "reward_avg_episodes": -47.741722106933594, "eplen_avg": 400.0, "captured_avg": 6.96875}, "eval_tst": {"reward_avg": -0.11875097662786714, "reward_avg_episodes": -47.50031280517578, "eplen_avg": 400.0, "captured_avg": 7.0859375}}
{"timestamp": 1761411258.8416338, "train_step": 300, "env_steps_total": 38400, "loss": 11.323512395222982, "grad_mean": 0.13313402384519576, "grad_min": 0.08662206927935283, "grad_max": 0.20978944003582, "entropy_mean": 6.113439785639445, "entropy_min": 6.007908344268799, "entropy_max": 6.227692763010661, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.11859472659521274, "reward_avg_episodes": -47.43781280517578, "eplen_avg": 400.0, "captured_avg": 6.9921875}, "eval_tst": {"reward_avg": -0.1195468750526199, "reward_avg_episodes": -47.81867218017578, "eplen_avg": 400.0, "captured_avg": 6.765625}}
{"timestamp": 1761411397.8301513, "train_step": 400, "env_steps_total": 51200, "loss": 11.68014939626058, "grad_mean": 0.14159485206007957, "grad_min": 0.09329406917095184, "grad_max": 0.20860321819782257, "entropy_mean": 6.129739093780517, "entropy_min": 6.070876121520996, "entropy_max": 6.2047882080078125, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.12038476566033214, "reward_avg_episodes": -48.15382766723633, "eplen_avg": 400.0, "captured_avg": 7.484375}, "eval_tst": {"reward_avg": -0.1205273437658033, "reward_avg_episodes": -48.21086502075195, "eplen_avg": 400.0, "captured_avg": 7.671875}}
{"timestamp": 1761411847.5209243, "train_step": 100, "env_steps_total": 12800, "loss": 10.846793174743652, "grad_mean": 0.18661898975570998, "grad_min": 0.09683121989170711, "grad_max": 0.2788682480653127, "entropy_mean": 6.036001221338909, "entropy_min": 4.835936546325684, "entropy_max": 6.243096987406413, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.12720117192924965, "reward_avg_episodes": -50.88038635253906, "eplen_avg": 400.0, "captured_avg": 6.5390625}, "eval_tst": {"reward_avg": -0.12833203127654255, "reward_avg_episodes": -51.33272171020508, "eplen_avg": 400.0, "captured_avg": 6.5625}}
{"timestamp": 1761411975.8703377, "train_step": 200, "env_steps_total": 25600, "loss": 11.15671189626058, "grad_mean": 0.15320313746730485, "grad_min": 0.10552882899840672, "grad_max": 0.2107553780078888, "entropy_mean": 6.1052046537399285, "entropy_min": 5.989564895629883, "entropy_max": 6.185205618540446, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.12078808600324566, "reward_avg_episodes": -48.315147399902344, "eplen_avg": 400.0, "captured_avg": 6.796875}, "eval_tst": {"reward_avg": -0.1213935547599103, "reward_avg_episodes": -48.557342529296875, "eplen_avg": 400.0, "captured_avg": 6.515625}}
{"timestamp": 1761412582.7583554, "train_step": 100, "env_steps_total": 12800, "loss": 11.634662946065268, "grad_mean": 0.20197909663120905, "grad_min": 0.09975810845692952, "grad_max": 0.36237987875938416, "entropy_mean": 6.028571405410767, "entropy_min": 4.81932258605957, "entropy_max": 6.215929667154948, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.11889062502497107, "reward_avg_episodes": -47.556175231933594, "eplen_avg": 400.0, "captured_avg": 7.9765625}, "eval_tst": {"reward_avg": -0.11846777347128949, "reward_avg_episodes": -47.387046813964844, "eplen_avg": 400.0, "captured_avg": 8.15625}}
{"timestamp": 1761413197.8512352, "train_step": 100, "env_steps_total": 12800, "loss": 11.464646975199381, "grad_mean": 0.18376507736742498, "grad_min": 0.09168003499507904, "grad_max": 0.29741543034712475, "entropy_mean": 5.988939582506814, "entropy_min": 4.821974754333496, "entropy_max": 6.223809242248535, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.12358593752124572, "reward_avg_episodes": -49.434303283691406, "eplen_avg": 400.0, "captured_avg": 7.25}, "eval_tst": {"reward_avg": -0.12231445314735173, "reward_avg_episodes": -48.92570114135742, "eplen_avg": 400.0, "captured_avg": 7.5078125}}
{"timestamp": 1761413448.20161, "train_step": 100, "env_steps_total": 12800, "loss": 11.480448087056478, "grad_mean": 0.19417546463509402, "grad_min": 0.09282609075307846, "grad_max": 0.30602027972539264, "entropy_mean": 6.018500599861145, "entropy_min": 4.841562271118164, "entropy_max": 6.199590841929118, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.12345214845941527, "reward_avg_episodes": -49.38079071044922, "eplen_avg": 400.0, "captured_avg": 7.3515625}, "eval_tst": {"reward_avg": -0.12441113284099256, "reward_avg_episodes": -49.76436996459961, "eplen_avg": 400.0, "captured_avg": 7.0078125}}
{"timestamp": 1761413700.2962856, "train_step": 100, "env_steps_total": 12800, "loss": 11.431233088175455, "grad_mean": 0.20657638438045978, "grad_min": 0.12018553664286931, "grad_max": 0.31054574251174927, "entropy_mean": 6.025549031893412, "entropy_min": 4.80479081471761, "entropy_max": 6.243982156117757, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.11577343753876632, "reward_avg_episodes": -46.30931091308594, "eplen_avg": 400.0, "captured_avg": 8.0546875}, "eval_tst": {"reward_avg": -0.11706152347961334, "reward_avg_episodes": -46.82453918457031, "eplen_avg": 400.0, "captured_avg": 7.71875}}
{"timestamp": 1761414161.618787, "train_step": 100, "env_steps_total": 12800, "loss": 11.397751808166504, "grad_mean": 0.19903750335176792, "grad_min": 0.10954376558462779, "grad_max": 0.3141917685667674, "entropy_mean": 5.99128845691681, "entropy_min": 4.817676226298015, "entropy_max": 6.1771799723307295, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.12216308597775072, "reward_avg_episodes": -48.86515808105469, "eplen_avg": 400.0, "captured_avg": 6.8046875}, "eval_tst": {"reward_avg": -0.12377929691094312, "reward_avg_episodes": -49.51163864135742, "eplen_avg": 400.0, "captured_avg": 6.28125}}
{"timestamp": 1761414292.4134266, "train_step": 200, "env_steps_total": 25600, "loss": 11.370100975036621, "grad_mean": 0.16583835800488791, "grad_min": 0.10776214798291524, "grad_max": 0.21722895403703055, "entropy_mean": 6.127416392962138, "entropy_min": 6.0236508051554365, "entropy_max": 6.222775936126709, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.1212001953475992, "reward_avg_episodes": -48.480003356933594, "eplen_avg": 400.0, "captured_avg": 7.515625}, "eval_tst": {"reward_avg": -0.12070410158135925, "reward_avg_episodes": -48.28156661987305, "eplen_avg": 400.0, "captured_avg": 7.625}}
{"timestamp": 1761414431.3167086, "train_step": 300, "env_steps_total": 38400, "loss": 11.470205624898275, "grad_mean": 0.1474154947201411, "grad_min": 0.09904414663712184, "grad_max": 0.24408559004465738, "entropy_mean": 6.158793678283692, "entropy_min": 6.056945323944092, "entropy_max": 6.22044022878011, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.12384863288028297, "reward_avg_episodes": -49.53937530517578, "eplen_avg": 400.0, "captured_avg": 7.0625}, "eval_tst": {"reward_avg": -0.12465625004624604, "reward_avg_episodes": -49.8624267578125, "eplen_avg": 400.0, "captured_avg": 6.890625}}
{"timestamp": 1761414567.0900238, "train_step": 400, "env_steps_total": 51200, "loss": 11.466350555419922, "grad_mean": 0.1403552519530058, "grad_min": 0.09673546999692917, "grad_max": 0.25276176631450653, "entropy_mean": 6.131368900934856, "entropy_min": 6.0201981862386065, "entropy_max": 6.197347640991211, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.11441796874246216, "reward_avg_episodes": -45.76713562011719, "eplen_avg": 400.0, "captured_avg": 8.953125}, "eval_tst": {"reward_avg": -0.11346777343319248, "reward_avg_episodes": -45.387062072753906, "eplen_avg": 400.0, "captured_avg": 9.3203125}}
{"timestamp": 1761414690.668833, "train_step": 500, "env_steps_total": 64000, "loss": 11.331103324890137, "grad_mean": 0.12446952037513258, "grad_min": 0.08511440455913544, "grad_max": 0.22595555086930594, "entropy_mean": 6.111638622283936, "entropy_min": 6.003309885660808, "entropy_max": 6.218644460042317, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.11854296877764868, "reward_avg_episodes": -47.417118072509766, "eplen_avg": 400.0, "captured_avg": 7.484375}, "eval_tst": {"reward_avg": -0.11686328126647276, "reward_avg_episodes": -46.74525451660156, "eplen_avg": 400.0, "captured_avg": 8.0546875}}
{"timestamp": 1761414821.574308, "train_step": 600, "env_steps_total": 76800, "loss": 11.200608253479004, "grad_mean": 0.1105055675903956, "grad_min": 0.0708688497543335, "grad_max": 0.185299222668012, "entropy_mean": 6.112442212104798, "entropy_min": 5.984943389892578, "entropy_max": 6.192678610483806, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.11998144533927553, "reward_avg_episodes": -47.99250793457031, "eplen_avg": 400.0, "captured_avg": 6.96875}, "eval_tst": {"reward_avg": -0.12004980472484014, "reward_avg_episodes": -48.01985168457031, "eplen_avg": 400.0, "captured_avg": 6.9296875}}
{"timestamp": 1761415983.163896, "train_step": 100, "env_steps_total": 12800, "loss": 11.8743044535319, "grad_mean": 0.2061337409168482, "grad_min": 0.09782282759745915, "grad_max": 0.2980501055717468, "entropy_mean": 6.016359051068623, "entropy_min": 4.798097133636475, "entropy_max": 6.319133281707764, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.12100683599212796, "reward_avg_episodes": -48.40266418457031, "eplen_avg": 400.0, "captured_avg": 7.6640625}, "eval_tst": {"reward_avg": -0.12023535158365861, "reward_avg_episodes": -48.09407043457031, "eplen_avg": 400.0, "captured_avg": 7.875}}
{"timestamp": 1761416110.3169572, "train_step": 200, "env_steps_total": 25600, "loss": 11.360463778177897, "grad_mean": 0.16048626348376274, "grad_min": 0.10551057507594426, "grad_max": 0.24346469342708588, "entropy_mean": 6.130446440378824, "entropy_min": 5.968615372975667, "entropy_max": 6.326123078664144, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.12299902345990983, "reward_avg_episodes": -49.199527740478516, "eplen_avg": 400.0, "captured_avg": 7.109375}, "eval_tst": {"reward_avg": -0.12282519533502644, "reward_avg_episodes": -49.1299934387207, "eplen_avg": 400.0, "captured_avg": 7.0234375}}
{"timestamp": 1761416242.8860884, "train_step": 300, "env_steps_total": 38400, "loss": 11.56900723775228, "grad_mean": 0.14831721253693103, "grad_min": 0.10412529607613881, "grad_max": 0.2162236968676249, "entropy_mean": 6.112614903450012, "entropy_min": 5.922357082366943, "entropy_max": 6.26647408803304, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.12631445315727613, "reward_avg_episodes": -50.52570343017578, "eplen_avg": 400.0, "captured_avg": 6.203125}, "eval_tst": {"reward_avg": -0.12478320316088505, "reward_avg_episodes": -49.91320037841797, "eplen_avg": 400.0, "captured_avg": 6.46875}}
{"timestamp": 1761416376.321961, "train_step": 400, "env_steps_total": 51200, "loss": 11.36627229054769, "grad_mean": 0.11970030290385088, "grad_min": 0.0883857732017835, "grad_max": 0.20316395660241446, "entropy_mean": 6.122066001892091, "entropy_min": 6.007754007975261, "entropy_max": 6.2383036613464355, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.12326757817799804, "reward_avg_episodes": -49.30696105957031, "eplen_avg": 400.0, "captured_avg": 7.46875}, "eval_tst": {"reward_avg": -0.12191601565841119, "reward_avg_episodes": -48.766334533691406, "eplen_avg": 400.0, "captured_avg": 8.0625}}
{"timestamp": 1761416508.3024757, "train_step": 500, "env_steps_total": 64000, "loss": 11.362776756286621, "grad_mean": 0.12895901923378308, "grad_min": 0.08873926848173141, "grad_max": 0.20436699191729227, "entropy_mean": 6.119552790323894, "entropy_min": 5.9905344645182295, "entropy_max": 6.243332386016846, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.12472167972222085, "reward_avg_episodes": -49.888580322265625, "eplen_avg": 400.0, "captured_avg": 6.65625}, "eval_tst": {"reward_avg": -0.12399609379030879, "reward_avg_episodes": -49.59835433959961, "eplen_avg": 400.0, "captured_avg": 6.8203125}}
{"timestamp": 1761416647.0323305, "train_step": 600, "env_steps_total": 76800, "loss": 11.252888043721518, "grad_mean": 0.13168418161571027, "grad_min": 0.09488147000471751, "grad_max": 0.2110294153292974, "entropy_mean": 6.128059306144715, "entropy_min": 6.03170379002889, "entropy_max": 6.2688852945963545, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.12498046879927274, "reward_avg_episodes": -49.99211120605469, "eplen_avg": 400.0, "captured_avg": 6.7734375}, "eval_tst": {"reward_avg": -0.1253720703308062, "reward_avg_episodes": -50.14875030517578, "eplen_avg": 400.0, "captured_avg": 6.7265625}}
{"timestamp": 1761416790.0685039, "train_step": 700, "env_steps_total": 89600, "loss": 11.534369786580404, "grad_mean": 0.13379932694137098, "grad_min": 0.08534650256236394, "grad_max": 0.2171053340037664, "entropy_mean": 6.133165855407716, "entropy_min": 5.990085124969482, "entropy_max": 6.249195257822673, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.12577929692939518, "reward_avg_episodes": -50.31163024902344, "eplen_avg": 400.0, "captured_avg": 7.09375}, "eval_tst": {"reward_avg": -0.12582617192168258, "reward_avg_episodes": -50.33039093017578, "eplen_avg": 400.0, "captured_avg": 7.0625}}
{"timestamp": 1761418201.671911, "train_step": 100, "env_steps_total": 12800, "loss": 11.659633954366049, "grad_mean": 0.20157502663632232, "grad_min": 0.10270222276449203, "grad_max": 0.3254188597202301, "entropy_mean": 6.032478440602622, "entropy_min": 4.836761315663655, "entropy_max": 6.243550777435303, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.12275976565791638, "reward_avg_episodes": -49.10382843017578, "eplen_avg": 400.0, "captured_avg": 7.4921875}, "eval_tst": {"reward_avg": -0.12300488284643492, "reward_avg_episodes": -49.201873779296875, "eplen_avg": 400.0, "captured_avg": 7.453125}}
{"timestamp": 1761418348.3018103, "train_step": 200, "env_steps_total": 25600, "loss": 11.732701301574707, "grad_mean": 0.1610461878279845, "grad_min": 0.10407473395268123, "grad_max": 0.2287654181321462, "entropy_mean": 6.119028518994651, "entropy_min": 5.994521617889404, "entropy_max": 6.20603084564209, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.11917968753416783, "reward_avg_episodes": -47.67180252075195, "eplen_avg": 400.0, "captured_avg": 7.3671875}, "eval_tst": {"reward_avg": -0.11986230471116138, "reward_avg_episodes": -47.944854736328125, "eplen_avg": 400.0, "captured_avg": 7.0703125}}
{"timestamp": 1761418476.6252124, "train_step": 300, "env_steps_total": 38400, "loss": 11.061298370361328, "grad_mean": 0.12273910686373708, "grad_min": 0.09160084525744121, "grad_max": 0.1769500027100245, "entropy_mean": 6.018363672892253, "entropy_min": 5.899096965789795, "entropy_max": 6.187208493550618, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.12785253912783814, "reward_avg_episodes": -51.140933990478516, "eplen_avg": 400.0, "captured_avg": 5.6484375}, "eval_tst": {"reward_avg": -0.1271230469280853, "reward_avg_episodes": -50.84913635253906, "eplen_avg": 400.0, "captured_avg": 5.78125}}
{"timestamp": 1761418593.701395, "train_step": 400, "env_steps_total": 51200, "loss": 10.839155197143555, "grad_mean": 0.11356850306193035, "grad_min": 0.08687420189380646, "grad_max": 0.16469459732373556, "entropy_mean": 5.922691567738851, "entropy_min": 5.8217794100443525, "entropy_max": 6.003392060597737, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.12457324223974141, "reward_avg_episodes": -49.82920455932617, "eplen_avg": 400.0, "captured_avg": 5.90625}, "eval_tst": {"reward_avg": -0.12331835942782365, "reward_avg_episodes": -49.3272590637207, "eplen_avg": 400.0, "captured_avg": 6.390625}}
{"timestamp": 1761418713.1333952, "train_step": 500, "env_steps_total": 64000, "loss": 11.090568860371908, "grad_mean": 0.11349387009938557, "grad_min": 0.07647392153739929, "grad_max": 0.15438921252886453, "entropy_mean": 5.967156321207681, "entropy_min": 5.865108172098796, "entropy_max": 6.052352587381999, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.12413769535167385, "reward_avg_episodes": -49.654991149902344, "eplen_avg": 400.0, "captured_avg": 6.09375}, "eval_tst": {"reward_avg": -0.12376953129371396, "reward_avg_episodes": -49.507728576660156, "eplen_avg": 400.0, "captured_avg": 6.15625}}
{"timestamp": 1761419081.5498428, "train_step": 100, "env_steps_total": 12800, "loss": 10.745722770690918, "grad_mean": 0.1778486019621293, "grad_min": 0.09911888341108958, "grad_max": 0.2873936394850413, "entropy_mean": 5.887905550003053, "entropy_min": 4.83534558614095, "entropy_max": 6.0596591631571455, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.13618066413426996, "reward_avg_episodes": -54.47217559814453, "eplen_avg": 400.0, "captured_avg": 3.4609375}, "eval_tst": {"reward_avg": -0.13593164070497732, "reward_avg_episodes": -54.37255096435547, "eplen_avg": 400.0, "captured_avg": 3.4140625}}
{"timestamp": 1761419194.8100293, "train_step": 200, "env_steps_total": 25600, "loss": 10.656294186909994, "grad_mean": 0.13868196020523707, "grad_min": 0.0901394858956337, "grad_max": 0.19789087772369385, "entropy_mean": 5.9313523785273246, "entropy_min": 5.843443552652995, "entropy_max": 6.03457244237264, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.12936035164110946, "reward_avg_episodes": -51.744049072265625, "eplen_avg": 400.0, "captured_avg": 3.578125}, "eval_tst": {"reward_avg": -0.13069921883047197, "reward_avg_episodes": -52.27959060668945, "eplen_avg": 400.0, "captured_avg": 3.2578125}}
{"timestamp": 1761419307.1325505, "train_step": 300, "env_steps_total": 38400, "loss": 10.801241874694824, "grad_mean": 0.13224931488434474, "grad_min": 0.09970518946647644, "grad_max": 0.16937648256619772, "entropy_mean": 5.963833479881287, "entropy_min": 5.8730878829956055, "entropy_max": 6.081556955973308, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.13559277352024213, "reward_avg_episodes": -54.23701858520508, "eplen_avg": 400.0, "captured_avg": 3.4453125}, "eval_tst": {"reward_avg": -0.13448242194988416, "reward_avg_episodes": -53.79287338256836, "eplen_avg": 400.0, "captured_avg": 3.5}}
{"timestamp": 1761419425.443807, "train_step": 400, "env_steps_total": 51200, "loss": 11.179664611816406, "grad_mean": 0.11024299013117948, "grad_min": 0.0743027279774348, "grad_max": 0.17383192479610443, "entropy_mean": 6.079723242123922, "entropy_min": 5.907198905944824, "entropy_max": 6.170308907826741, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.13395703133803896, "reward_avg_episodes": -53.582725524902344, "eplen_avg": 400.0, "captured_avg": 3.46875}, "eval_tst": {"reward_avg": -0.13445898444243362, "reward_avg_episodes": -53.78351593017578, "eplen_avg": 400.0, "captured_avg": 3.3046875}}
{"timestamp": 1761419546.5877893, "train_step": 500, "env_steps_total": 64000, "loss": 11.209402084350586, "grad_mean": 0.11725668579339982, "grad_min": 0.0746648907661438, "grad_max": 0.16720170279343924, "entropy_mean": 6.116150118509929, "entropy_min": 6.011125723520915, "entropy_max": 6.234384854634603, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.13268261723982877, "reward_avg_episodes": -53.072959899902344, "eplen_avg": 400.0, "captured_avg": 3.2265625}, "eval_tst": {"reward_avg": -0.1329746094307628, "reward_avg_episodes": -53.18975830078125, "eplen_avg": 400.0, "captured_avg": 3.0546875}}
{"timestamp": 1761681812.5439034, "train_step": 100, "env_steps_total": 12800, "loss": 10.912104288736979, "grad_mean": 0.30326722589631877, "grad_min": 0.08893002818028133, "grad_max": 0.47458640734354657, "entropy_mean": 5.875508238474529, "entropy_min": 4.7908585866292315, "entropy_max": 6.11983076731364, "lr": 0.0015, "alpha_h": 0.3, "eval_trn": {"reward_avg": -0.18820898437694988, "reward_avg_episodes": -75.28341674804688, "eplen_avg": 400.0, "captured_avg": 6.4609375}, "eval_tst": {"reward_avg": -0.1871064453306606, "reward_avg_episodes": -74.84239196777344, "eplen_avg": 400.0, "captured_avg": 6.4609375}}
