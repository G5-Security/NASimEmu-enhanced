# ğŸŒŸ RL Architecture Performance Comparison

This document presents a comprehensive comparative analysis of different RL architectures on NASim scenarios. Each architecture is evaluated on training and testing scenarios to assess generalization capabilities and performance characteristics.

## ğŸ“Š Executive Summary

| ğŸ—ï¸ Architecture | ğŸ¯ Train Performance | ğŸ§ª Test Performance | ğŸ“ˆ Generalization | ğŸ† Overall Rank |
|------------------|---------------------|---------------------|-------------------|-----------------|
| **GNN** | â­â­â­â­â­ (3.36 hosts) | â­â­â­â­â­ (2.89 hosts) | ğŸŸ¢ **Excellent** | ğŸ¥‡ **1st** |
| **Attention** | â­â­â­â­â­ (3.58 hosts) | â­â­â­â­ (2.16 hosts) | ğŸŸ¡ **Good** | ğŸ¥ˆ **2nd** |
| **Invariant** | â­â­â­â­ (3.31 hosts) | â­â­â­ (1.88 hosts) | ğŸŸ¡ **Good** | ğŸ¥‰ **3rd** |
| **MLP** | â­â­ (1.19 hosts) | â­ (0.13 hosts) | ğŸ”´ **Poor** | 4th |

### ğŸ¯ Key Insights
- **GNN dominates with best test performance** (2.89 hosts) and excellent generalization (86% retention)
- **Attention achieves highest training performance** (3.58 hosts) but lower test performance (2.16 hosts)
- **Invariant provides balanced performance** with good parameter efficiency
- **Episode efficiency**: Attention (31 steps) > GNN (32 steps) > Invariant (36 steps) > MLP (100 steps)
---


## ğŸ§  1. Multi-Layer Perceptron (MLP)

### ğŸ—ï¸ Model Architecture

```python
NASimNetMLP(
  (mlp): Sequential(
    (0): Linear(in_features=2250, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
  )
  (action_select): Linear(in_features=64, out_features=500, bias=True)
  (value_function): Linear(in_features=64, out_features=1, bias=True)
)
# Parameters: 180,789
```

<details>
<summary><strong>ğŸ”§ Common Configuration</strong> (click to expand)</summary>

| Parameter           | Value  |
| ------------------- | ------ |
| gamma               | 0.99   |
| batch               | 128    |
| epoch               | 1000   |
| ppo_k               | 3      |
| ppo_t               | 8      |
| ppo_eps             | 0.2    |
| alpha_v             | 0.0333 |
| alpha_h             | 0.3    |
| opt_lr              | 0.003  |
| opt_l2              | 0.0001 |
| opt_max_norm        | 3.0    |
| emb_dim             | 64     |
| mp_iterations       | 3      |
| pos_enc_dim         | 8      |
| action_dim          | 10     |
| node_dim            | 46     |
| step_limit          | 100    |
| augment_with_action | True   |
| use_a_t             | True   |

</details>

---

### ğŸ¯ 1.1 Training Scenario: <code>uni.v2.yaml</code>

**Command:**

```bash
python main.py ../scenarios/uni.v2.yaml --eval -load_model wandb/mlp_2_complete/files/model.pt -net_class NASimNetMLP -use_a_t -episode_step_limit 100 -augment_with_action
```

**Results:**

| ğŸ… Metric           | ğŸ”¢ Value |
| ------------------- | -------- |
| Avg. Reward         | 0.0187   |
| Avg. Reward/Episode | 1.875    |
| Avg. Episode Length | 100.0    |
| Avg. Captured       | 1.19     |

---

### ğŸ§ª 1.2 Test Scenario: <code>corp.v2.yaml</code>

**Command:**

```bash
python main.py ../scenarios/corp.v2.yaml --eval -load_model wandb/mlp_2_complete/files/model.pt -net_class NASimNetMLP -use_a_t -episode_step_limit 100 -augment_with_action
```

**Results:**

| ğŸ… Metric           | ğŸ”¢ Value |
| ------------------- | -------- |
| Avg. Reward         | -0.0875  |
| Avg. Reward/Episode | -8.75    |
| Avg. Episode Length | 100.0    |
| Avg. Captured       | 0.13     |

---

### ğŸ“Š MLP Performance Analysis

| ğŸ… Metric           | ğŸ¯ Train | ğŸ§ª Test | ğŸ“‰ Drop | ğŸ“ˆ Retention |
| ------------------- | -------- | ------- | ------- | ------------ |
| Avg. Reward         | 0.0187   | -0.0875 | -0.1062 | **-468%** ğŸ”´ |
| Avg. Reward/Episode | 1.875    | -8.75   | -10.625 | **-467%** ğŸ”´ |
| Avg. Episode Length | 100.0    | 100.0   | 0.0     | **100%** ğŸŸ¢  |
| Avg. Captured       | 1.19     | 0.13    | -1.06   | **11%** ğŸ”´   |

**ğŸ” Analysis:** MLP shows severe overfitting with negative test performance. Poor generalization indicates the model memorized training patterns rather than learning transferable strategies.

---

## ğŸ§© 2. Graph Neural Network (GNN)

### ğŸ—ï¸ Model Architecture

```python
NASimNetGNN_MAct(
  (embed_node): Sequential(
    (0): Linear(in_features=54, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
  )
  (gnn): MultiMessagePassingWithGlobalNode(
    (gnns): ModuleList(
      (0-1): 2 x GraphNet()
    )
    (pools): ModuleList(
      (0-1): 2 x GlobalNode(
        (glob): GlobalAttention(gate_nn=Linear(in_features=64, out_features=1, bias=True), nn=Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): LeakyReLU(negative_slope=0.01)
        ))
        (tranform): Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): LeakyReLU(negative_slope=0.01)
        )
      )
    )
  )
  (action_select): Linear(in_features=64, out_features=10, bias=True)
  (value_function): Linear(in_features=64, out_features=1, bias=True)
)
# Parameters: 62,221
```

<details>
<summary><strong>ğŸ”§ Common Configuration</strong> (click to expand)</summary>

| Parameter           | Value    |
| ------------------- | -------- |
| gamma               | 0.99     |
| batch               | 128      |
| epoch               | 1000     |
| ppo_k               | 3        |
| ppo_t               | 8        |
| ppo_eps             | 0.2      |
| alpha_v             | 0.0333   |
| alpha_h             | 0.3      |
| opt_lr              | 0.003    |
| opt_l2              | 0.0001   |
| opt_max_norm        | 3.0      |
| emb_dim             | 64       |
| mp_iterations       | 2        |
| pos_enc_dim         | 8        |
| action_dim          | 10       |
| node_dim            | 46       |
| step_limit          | 100      |
| augment_with_action | True     |
| use_a_t             | True     |
| observation_format  | graph_v2 |

</details>

---

### ğŸ¯ 2.1 Training Scenario: <code>uni.v2.yaml</code>

**Command:**

```bash
python main.py ../scenarios/uni.v2.yaml --eval \
  -load_model wandb/gnn_2_complete/files/model.pt \
  -net_class NASimNetGNN_MAct \
  -observation_format graph_v2 \
  -mp_iterations 2 \
  -use_a_t \
  -episode_step_limit 100 \
  -augment_with_action
```

**Results:**

| ğŸ… Metric           | ğŸ”¢ Value |
| ------------------- | -------- |
| Avg. Reward         | 0.9408   |
| Avg. Reward/Episode | 30.43    |
| Avg. Episode Length | 32.34    |
| Avg. Captured       | 3.36     |

---

### ğŸ§ª 2.2 Test Scenario: <code>corp.v2.yaml</code>

**Command:**

```bash
python main.py ../scenarios/corp.v2.yaml --eval \
  -load_model wandb/gnn_2_complete/files/model.pt \
  -net_class NASimNetGNN_MAct \
  -observation_format graph_v2 \
  -mp_iterations 2 \
  -use_a_t \
  -episode_step_limit 100 \
  -augment_with_action
```

**Results:**

| ğŸ… Metric           | ğŸ”¢ Value |
| ------------------- | -------- |
| Avg. Reward         | 0.5181   |
| Avg. Reward/Episode | 24.29    |
| Avg. Episode Length | 46.89    |
| Avg. Captured       | 2.89     |

---

### ğŸ“Š GNN Performance Analysis

| ğŸ… Metric           | ğŸ¯ Train | ğŸ§ª Test | ğŸ“‰ Drop | ğŸ“ˆ Retention |
| ------------------- | -------- | ------- | ------- | ------------ |
| Avg. Reward         | 0.9408   | 0.5181  | -0.4227 | **55%** ğŸŸ¢   |
| Avg. Reward/Episode | 30.43    | 24.29   | -6.14   | **80%** ğŸŸ¢   |
| Avg. Episode Length | 32.34    | 46.89   | +14.55  | **69%** ğŸŸ¡   |
| Avg. Captured       | 3.36     | 2.89    | -0.47   | **86%** ğŸŸ¢   |

**ğŸ” Analysis:** GNN demonstrates excellent generalization with 86% host capture retention. The model learns highly transferable network attack strategies, maintaining strong performance across different network topologies.

---

## ğŸ”§ 3. Invariant Network (Invariant)

### ğŸ—ï¸ Model Architecture

```python
NASimNetInvMAct(
  (embed_node): Sequential(
    (0): Linear(in_features=53, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
  )
  (inner): Sequential(
    (0): Linear(in_features=128, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
  )
  (action_select): Linear(in_features=128, out_features=10, bias=True)
  (value_function): Linear(in_features=64, out_features=1, bias=True)
)
# Parameters: 13,067
```

<details>
<summary><strong>ğŸ”§ Common Configuration</strong> (click to expand)</summary>

| Parameter           | Value  |
| ------------------- | ------ |
| gamma               | 0.99   |
| batch               | 128    |
| epoch               | 1000   |
| ppo_k               | 3      |
| ppo_t               | 8      |
| ppo_eps             | 0.2    |
| alpha_v             | 0.0333 |
| alpha_h             | 0.3    |
| opt_lr              | 0.003  |
| opt_l2              | 0.0001 |
| opt_max_norm        | 3.0    |
| emb_dim             | 64     |
| mp_iterations       | 3      |
| pos_enc_dim         | 8      |
| action_dim          | 10     |
| node_dim            | 46     |
| step_limit          | 100    |
| augment_with_action | True   |
| use_a_t             | True   |

</details>

---

### ğŸ¯ 3.1 Training Scenario: <code>uni.v2.yaml</code>

**Command:**

```bash
python main.py ../scenarios/uni.v2.yaml --eval \
  -load_model wandb/latest-run/files/model.pt \
  -net_class NASimNetInvMAct \
  -use_a_t \
  -episode_step_limit 100 \
  -augment_with_action
```

**Results:**

| ğŸ… Metric           | ğŸ”¢ Value |
| ------------------- | -------- |
| Avg. Reward         | 0.8103   |
| Avg. Reward/Episode | 29.52    |
| Avg. Episode Length | 36.44    |
| Avg. Captured       | 3.31     |

---

### ğŸ§ª 3.2 Test Scenario: <code>corp.v2.yaml</code>

**Command:**

```bash
python main.py ../scenarios/corp.v2.yaml --eval \
  -load_model wandb/latest-run/files/model.pt \
  -net_class NASimNetInvMAct \
  -use_a_t \
  -episode_step_limit 100 \
  -augment_with_action
```

**Results:**

| ğŸ… Metric           | ğŸ”¢ Value |
| ------------------- | -------- |
| Avg. Reward         | 0.1935   |
| Avg. Reward/Episode | 12.42    |
| Avg. Episode Length | 64.17    |
| Avg. Captured       | 1.88     |

---

### ğŸ“Š Invariant Performance Analysis

| ğŸ… Metric           | ğŸ¯ Train | ğŸ§ª Test | ğŸ“‰ Drop | ğŸ“ˆ Retention |
| ------------------- | -------- | ------- | ------- | ------------ |
| Avg. Reward         | 0.8103   | 0.1935  | -0.6168 | **24%** ğŸŸ¡   |
| Avg. Reward/Episode | 29.52    | 12.42   | -17.10  | **42%** ğŸŸ¡   |
| Avg. Episode Length | 36.44    | 64.17   | +27.73  | **57%** ğŸŸ¡   |
| Avg. Captured       | 3.31     | 1.88    | -1.43   | **57%** ğŸŸ¡   |

**ğŸ” Analysis:** Invariant network shows moderate generalization with 57% host capture retention. The model demonstrates balanced performance between MLP and GNN, with reasonable efficiency and parameter count.

---

## ğŸ¯ 4. Attention Network (Attention)

### ğŸ—ï¸ Model Architecture

```python
NASimNetXAttMAct(
  (embed_node): Sequential(
    (0): Linear(in_features=53, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
  )
  (xatt): MultiheadAttention(
    (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
  )
  (action_select): Linear(in_features=128, out_features=10, bias=True)
  (value_function): Linear(in_features=128, out_features=1, bias=True)
)
# Parameters: 21,515
```

<details>
<summary><strong>ğŸ”§ Common Configuration</strong> (click to expand)</summary>

| Parameter           | Value  |
| ------------------- | ------ |
| gamma               | 0.99   |
| batch               | 128    |
| epoch               | 1000   |
| ppo_k               | 3      |
| ppo_t               | 8      |
| ppo_eps             | 0.2    |
| alpha_v             | 0.0333 |
| alpha_h             | 0.3    |
| opt_lr              | 0.003  |
| opt_l2              | 0.0001 |
| opt_max_norm        | 3.0    |
| emb_dim             | 64     |
| mp_iterations       | 3      |
| pos_enc_dim         | 8      |
| action_dim          | 10     |
| node_dim            | 46     |
| step_limit          | 100    |
| augment_with_action | True   |
| use_a_t             | True   |

</details>

---

### ğŸ¯ 4.1 Training Scenario: <code>uni.v2.yaml</code>

**Command:**

```bash
python main.py ../scenarios/uni.v2.yaml --eval \
  -load_model wandb/latest-run/files/model.pt \
  -net_class NASimNetXAttMAct \
  -use_a_t \
  -episode_step_limit 100 \
  -augment_with_action
```

**Results:**

| ğŸ… Metric           | ğŸ”¢ Value |
| ------------------- | -------- |
| Avg. Reward         | 1.0524   |
| Avg. Reward/Episode | 32.83    |
| Avg. Episode Length | 31.19    |
| Avg. Captured       | 3.58     |

---

### ğŸ§ª 4.2 Test Scenario: <code>corp.v2.yaml</code>

**Command:**

```bash
python main.py ../scenarios/corp.v2.yaml --eval \
  -load_model wandb/latest-run/files/model.pt \
  -net_class NASimNetXAttMAct \
  -use_a_t \
  -episode_step_limit 100 \
  -augment_with_action
```

**Results:**

| ğŸ… Metric           | ğŸ”¢ Value |
| ------------------- | -------- |
| Avg. Reward         | 0.2743   |
| Avg. Reward/Episode | 15.87    |
| Avg. Episode Length | 57.87    |
| Avg. Captured       | 2.16     |

---

### ğŸ“Š Attention Performance Analysis

| ğŸ… Metric           | ğŸ¯ Train | ğŸ§ª Test | ğŸ“‰ Drop | ğŸ“ˆ Retention |
| ------------------- | -------- | ------- | ------- | ------------ |
| Avg. Reward         | 1.0524   | 0.2743  | -0.7781 | **26%** ğŸŸ¡   |
| Avg. Reward/Episode | 32.83    | 15.87   | -16.96  | **48%** ğŸŸ¡   |
| Avg. Episode Length | 31.19    | 57.87   | +26.68  | **54%** ğŸŸ¡   |
| Avg. Captured       | 3.58     | 2.16    | -1.42   | **60%** ğŸŸ¡   |

**ğŸ” Analysis:** Attention network achieves the highest training performance but shows moderate generalization with 60% host capture retention. The model excels at learning complex patterns but requires more steps in unfamiliar environments.

---

---

## ğŸ† Architecture Comparison Summary

### ğŸ¥‡ **Winner: Graph Neural Network (GNN)**

- **ğŸ¯ Best Overall Balance**: 3.36 hosts captured with excellent generalization
- **ğŸ§  Excellent Generalization**: 86% performance retention (best)
- **âš¡ High Efficiency**: 32 steps per episode
- **ğŸ’¾ Good Parameter Efficiency**: 62K parameters with optimal results

### ğŸ¥ˆ **Runner-up: Attention Network**

- **ğŸ¯ Highest Training Performance**: 3.58 hosts captured (peak performance)
- **ğŸ§  Good Generalization**: 60% performance retention
- **âš¡ Highest Efficiency**: 31 steps per episode (fastest)
- **ğŸ’¾ Compact Architecture**: 21K parameters with strong results

### ğŸ¥‰ **Third Place: Invariant Network**

- **ğŸ¯ Solid Performance**: 3.31 hosts captured (consistent)
- **ğŸ§  Moderate Generalization**: 57% performance retention
- **âš¡ Good Efficiency**: 36 steps per episode
- **ğŸ’¾ Most Parameter Efficient**: Only 13K parameters

### **Fourth Place: Multi-Layer Perceptron (MLP)**

- **âœ… Fastest Training**: Simpler architecture trains quickest
- **âŒ Poor Generalization**: Severe overfitting (11% retention)
- **âŒ Least Efficient**: Always uses maximum episode length (100 steps)
- **âŒ Parameter Heavy**: 181K parameters for worst results

---

## ğŸ“Š Enhanced Performance Visualization

The comprehensive performance comparison includes:

- **ğŸ“ˆ Individual metric comparisons** with value labels
- **ğŸ¯ Generalization analysis** showing retention percentages
- **ğŸ“‹ Summary statistics table** with rankings
- **ğŸ’¡ Key insights** and architectural highlights

![Model Performance Comparison](model_performance_comparison.png)

**Generate the enhanced visualization:**

```bash
python model_performance_comparison.py
```

---

## ğŸ“ Experimental Details

- ğŸ“Š **Evaluation**: 128 problems per scenario
- ğŸ¯ **Training Scenario**: `uni.v2.yaml` (University network)
- ğŸ§ª **Test Scenario**: `corp.v2.yaml` (Corporate network)
- âš™ï¸ **Configuration**: Consistent hyperparameters across architectures
- ğŸ“ˆ **Metrics**: Reward, episode length, host capture rate
- ğŸ”„ **Reproducibility**: Fixed seeds and deterministic evaluation